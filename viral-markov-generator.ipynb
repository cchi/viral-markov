{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Viral and attention-grabbing headlines are certainly intriguing. I definitely fell for clickbait countless times! I suspect there is a formula to generating eye-catching, click-worthy headlines. Wouldn't it be great if we leveraged algorithms to tease apart some of this hidden structure within viral headlines? Well, this is what this exploration is all about. :)</p>\n",
    "<p>The goal of this notebook is to demonstrate creation of simple Markov chain to generate viral headlines using real examples to build its vocabulary.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>Firstly, a big thank you to the wonderful folks over at <a href=\"http://www.ripenn.com/\">Ripenn</a> for providing a neat corpus. Data is available for download at end of this post: \"<a href=\"http://www.ripenn.com/blog/7-things-marketers-can-learn-from-2616-viral-headlines/\">7 Things Marketers Can Learn From 2,616 Viral Headlines</a>\".\n",
    "</p>\n",
    "<p>\n",
    "I discovered this dataset which was referenced in <a href='https://blog.bufferapp.com/' >Buffersocial</a>'s post \"<a href=\"https://blog.bufferapp.com/the-most-popular-words-in-most-viral-headlines\">How to Write The Perfect Headline: The Top Words Used in Viral Headlines</a>\"\n",
    ".</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My inspiration for building a Markov chain originated from these two posts:\n",
    "    <li>\"<a href=\"http://agiliq.com/blog/2009/06/generating-pseudo-random-text-with-markov-chains-u/\">Generating pseudo random text with Markov chains using Python</a>\"</li>\n",
    "    <li>\"<a href=\"http://www.onthelambda.com/2014/02/20/how-to-fake-a-sophisticated-knowledge-of-wine-with-markov-chains/\">How to fake a sophisticated knowledge of wine with Markov Chains</a>\"</li>\n",
    "<p>I learned a great amount from these demonstrations, they're definitely worth visit. In this notebook, I assimilated some of their techniques and with my own experience working with text data. Thanks to Shabda Raaj and Tony Fischetti.</p>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import ftfy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>loading headlines into Pandas DataFrame</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sheetnames = ['Buzzfeed', 'ViralNova', 'Upworthy', 'Wimp', 'Feedly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buzzfeed\n",
      "ViralNova\n",
      "Upworthy\n",
      "Wimp\n",
      "Feedly\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for sheetname in sheetnames:\n",
    "    print(sheetname)\n",
    "    dfs = pd.read_excel( r'data/Viral-Title-Analysis-ripenn.xlsx', sheetname=sheetname )\n",
    "    dfs['sheetname'] = sheetname\n",
    "    df = pd.concat( [df, dfs], ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([               u'+1s',         u'CHAR COUNT',          u'Delicious',\n",
       "                    u'Diggs',        u'FB Comments',           u'FB Likes',\n",
       "                u'FB Shares',           u'FB Total',       u'FIRST PERSON',\n",
       "                     u'Link',    u'LinkedIn Shares',           u'NEGATIVE',\n",
       "                   u'NUMBER',               u'Pins',           u'QUESTION',\n",
       "                   u'Reddit', u'SEXUAL ORIENTATION',               u'SITE',\n",
       "              u'StumbleUpon',              u'TITLE',             u'Tweets',\n",
       "                      u'URL',                u'WHY',          u'sheetname'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to perform some dataframe reconfiguration. Upon examining the raw data in excel, one can observe that:\n",
    "<li>for sheetnames 'Buzzfeed', 'ViralNova', and 'Upworthy', headlines are under 'TITLE'</li>\n",
    "<li>for sheetnames 'Wimp' and 'Feedly', the column label 'Link' actually contained the headlines. </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[['TITLE', 'Link', 'sheetname']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['headline'] = df['TITLE']\n",
    "df['headline'].fillna(df['Link'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>preprocess text and get headlines to a list</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# walkthru how I arrived at removal/cleaning heuristic; this step required some back and forth to get the headlines in a cleaner format... \n",
    "replacements = { u'\\xa0': u' ',     # non-breaking space\n",
    "                 u'\\u2026': u'...', # horizontal ellipsis\n",
    "                 u'\\u201c': u'\"',   # left double quotation\n",
    "                 u'\\u201d': u'\"'    # right double quotation\n",
    "               }\n",
    "\n",
    "def clean( s ):\n",
    "    s = ftfy.fix_text(s)\n",
    "    for old, new in replacements.items():\n",
    "        s = s.replace( old, new )\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headlines = df['headline'].apply(lambda x: clean(x)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Birds Do This All The Time. But Seeing It Actually Happen Is Pretty Awesome.',\n",
       " u'This 12 Year Old Girl Just Died. The Letter Her Parents Discovered Afterwards Is Heart Shattering.',\n",
       " u'Childhood Amnesia: The Age at Which Our Earliest Memories Fade',\n",
       " u'Two projectors create a real-life skinning effect on a simple, white living room.',\n",
       " u'10 Ways For 2013 Not To Suck',\n",
       " u'Facebook Call-to-Action Buttons: Everything You Need to Know [Video]',\n",
       " u'Godzilla roar is actually a leather glove being dragged down the strings of a bass.',\n",
       " u\"18 Things You Need To Know About California's Worst Drought In Centuries\",\n",
       " u\"World's deadliest hamburger.\",\n",
       " u'Methinks The Anti-Gay Politician Doth Protest Too Much',\n",
       " u\"The 'Tip' They Left This Waitress Is Disgusting. And She Even Fought For Her Country.\",\n",
       " u'25 Sneaky Online Tools and Gadgets to Help You Spy on Your Competitors',\n",
       " u\"I'm So Glad There Was A Camera On This Baby Elephant At The Perfect Time. Because This Is The Best.\",\n",
       " u'This Guy Took My Favorite Two Things As A Child... And Made Them Even More Epic.',\n",
       " u\"Pilot's View: Airbus A380 approach and landing at San Francisco.\"]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample( headlines, 15 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>creating a class for Markov chain</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Markov(object):\n",
    "    def __init__(self, lst):\n",
    "        self.d = {}\n",
    "        self.sentences = self.tokenize_sentences( lst )\n",
    "        self.create_dict()\n",
    "        \n",
    "    def tokenize_sentences(self, lst):\n",
    "        return [nltk.word_tokenize(s) for s in lst]\n",
    "        \n",
    "    def create_dict(self):\n",
    "        for s in self.sentences:\n",
    "            for w1, w2, w3 in self.trigram(s):\n",
    "                k = (w1, w2)\n",
    "                if k not in self.d:\n",
    "                    self.d[k] = []\n",
    "                self.d[k].append(w3)\n",
    "    \n",
    "    def trigram(self, tokens):\n",
    "        if len(tokens) < 3:\n",
    "            return\n",
    "        for i in xrange(len(tokens) - 2):\n",
    "            yield tokens[i], tokens[i+1], tokens[i+2]\n",
    "    \n",
    "    def generate( self, size=15 ):\n",
    "        # pick a random sentence\n",
    "        i = random.randint(0, len(self.sentences) - 1)\n",
    "        sentence = self.sentences[ i ]\n",
    "        \n",
    "        # pick two random sequential words from the sentence\n",
    "        i = random.randint(0, len(sentence) - 2)\n",
    "        w1, w2 = sentence[ i ], sentence[ i+1 ]\n",
    "\n",
    "        return self.generate_from_words( w1, w2, size=size )\n",
    "        \n",
    "    def generate_from_words( self, w1, w2, size=15 ):\n",
    "        outcome = []\n",
    "        for i in xrange(size):\n",
    "            outcome.append(w1)\n",
    "            k = (w1, w2)\n",
    "            \n",
    "            if k not in self.d:\n",
    "                break\n",
    "            else:\n",
    "                w1, w2 = w2, random.choice( self.d[k] )\n",
    "        outcome.append(w2)  \n",
    "        return ' '.join(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = Markov( headlines )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "examining the internal dictionary that is generated from the headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21059"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m.d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'Toowoomba', u','), [u'Australia']),\n",
       " ((u'Beginners', u'Guide'), [u'to']),\n",
       " ((u'Baby', u'elephant'), [u'tries']),\n",
       " ((u'Set', u'on'), [u'Fire']),\n",
       " ((u'Go', u'Now'), [u'.']),\n",
       " ((u'Notebook', u\"''\"), [u'And']),\n",
       " ((u'in', u'the'),\n",
       "  [u'Act',\n",
       "   u'Eyes',\n",
       "   u'Most',\n",
       "   u'Face',\n",
       "   u'Emergency',\n",
       "   u'Same',\n",
       "   u'mid',\n",
       "   u'US',\n",
       "   u'Amazon',\n",
       "   u'Copenhagen',\n",
       "   u'white',\n",
       "   u'wall',\n",
       "   u'sun',\n",
       "   u'Sky',\n",
       "   u'universe',\n",
       "   u'Face',\n",
       "   u'Mundane',\n",
       "   u'Room',\n",
       "   u'Right',\n",
       "   u'Margin',\n",
       "   u'Facebook']),\n",
       " ((u'Your', u'Head'), [u'In', u'.']),\n",
       " ((u'Insane', u'Fast'), [u'Food']),\n",
       " ((u'Dog', u'Breeds'), [u'You']),\n",
       " ((u'Child', u'Noticed'), [u'In']),\n",
       " ((u'The', u'Moon'), [u'(']),\n",
       " ((u'On', u'Humanity'), [u',']),\n",
       " ((u'Living', u'You'), [u'Learned']),\n",
       " ((u'Next', u'Obama'), [u'Could'])]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample( m.d.items(), 15 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Generating random headlines</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Bestie You Love Says About You And How It Can Your\n",
      "To Follow Instructions ... And I Still Ca n't Steal Love . The Folks Dismantling Wear\n",
      "A Woman Gets Sick Of Divorce And Mortgages . And Most Accurate History Of The 19th Century\n",
      "Want You To Be Caged For 4 Decades ?\n",
      "Steffi Graf receives a pleasant surprise during a college football game .\n",
      "The Office\n",
      "' Explained In Under 60 Seconds . These 'Before And '\n",
      "subway project in NYC .\n",
      "Do n't Allow Animals Inside . It 's A Good Cuddle\n",
      "The 29 Most New Zealand Moments Ever\n",
      "Role ? Replacing Andy Samberg In British Sitcom `` Cuckoo ''\n",
      "Christmas Creation Of All The Places His Little Boy Stared a Terrorist in the mid late\n",
      "Your Presidential Candidate\n",
      "Ranking Of Disney Love Songs\n",
      "Was Arrested 20 Times For This . Wow . Watch These Rhinos Fly ! Much Endangered .\n"
     ]
    }
   ],
   "source": [
    "for _ in xrange(15):\n",
    "    size = random.randint(10, 20)\n",
    "    print(m.generate(size=size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Priming with two starter words of my choice</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Is Awesome . I 've Ever Cried This Hard Especially\n",
      "This Is ANGELIC . And It 's Not The Unbelievable Loophole In U.S. Child Labor Law\n",
      "This Is Hilarious . LOLOLOL .\n",
      "This Is Why You 're Damned Right The Government Wants You To See This . Neither Did My Heart This\n",
      "This Is So Perfect That It Made Me Cry A Bucket Of Tears . All\n",
      "This Is Okay ? Unbelievable . Seriously , Stop What You Expect . OMG . Google Carlson\n",
      "This Is Your Ideal Relationship ?\n",
      "This Is Awesome . I 'm Glad I Saw This . Especially If You Hate It A Dog Still\n",
      "This Is Crazy . These Are GREAT .\n",
      "This Is The Funniest Thing You 'll Probably Agree .\n"
     ]
    }
   ],
   "source": [
    "for _ in xrange(10):\n",
    "    size = random.randint(10, 20)\n",
    "    print( m.generate_from_words( 'This', 'Is', size=size ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why Is Even More Unbelievable . Seriously .\n",
      "Why Is Unforgettable . The Letter Her Parents Discovered Afterwards Is Shattering\n",
      "Why Is Even A Thing . So His Mom . The It\n",
      "Why Is Even More Absurd .\n",
      "Why Is Something That Is Barely Being Talked About\n",
      "Why Is Even More Disturbing Than It Looks Like A Typical With\n",
      "Why Is Absurd .\n",
      "Why Is YOUR Member Of Congress — They 're Brilliant . OMG Google\n",
      "Why Is Google Sleeping With That Jerk ?\n",
      "Why Is This Arrested Woman So Happy ?\n"
     ]
    }
   ],
   "source": [
    "for _ in xrange(10):\n",
    "    size = random.randint(10, 20)\n",
    "    print( m.generate_from_words( 'Why', 'Is', size=size ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>The Good</i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Sharing His Text To Kendrick Lamar</li>\n",
    "<li>7 Alarming Facts Essentially Say : Women Are Biased Toward Thinking They Are Eerie .</li>\n",
    "<li>, This Will Make You Cry . But THIS is Insanity .</li>\n",
    "<li>What Happened Next Will Shock You . That 's Actually A Completely Brilliant Idea !</li>\n",
    "<li>This May Be Wrong . Reality Check .</li>\n",
    "<li>For Aliens That Want To Check This Out . Freaky .</li>\n",
    "<li>Any Of It Is Breathtaking .</li>\n",
    "<li>Black Girls Code . Simple Name , Revolutionary Premise .</li>\n",
    "<li>This Is Awesomely Weird . Then I Saw How He Did . And I LOVE .</li>\n",
    "<li>When You Can Only Buy At A Party ... LOL .</li>\n",
    "<li>12 of the Strangest Weather-Related Photographs Ever Taken . Wow . Watch These Rhinos Fly !</li>\n",
    "<li>Be Prepared To Change What You Were Expecting</li>\n",
    "<li>Romney 's Own Mother Undermines His Entire Campaign</li>\n",
    "<li>Which Vladimir Putin Tattoos Are Works Of Refrigerator Door Art</li>\n",
    "<li>This Is Every Bit As Awesome As It Looks Like At 4,000 Frames Per Second</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>The Bad</i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Stuffed Animal . It 's Hard Not To Run For President</li>\n",
    "<li>Your First Apartment</li>\n",
    "<li>Well In Museums</li>\n",
    "<li>Perfect Roommate</li>\n",
    "<li>Ghosts , You Will Love It . You Probably Forgot About</li>\n",
    "<li>Wo n't Have Gotten Married At All Times . When He Returned 30 Minutes Later Something</li>\n",
    "<li> Endangered</li>\n",
    "<li># ing Message</li>\n",
    "<li>Closer ... WHAT ? !</li>\n",
    "<li>Future Is NOT After</li>\n",
    "<li>Fracking ?</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>The Ugly</i></b> (These made me laugh... some of these where imperfect/incomplete but totally left me hanging!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>'ll Ever See . And The Internet , Democracy Is NOT Doomed After Falling Through ...</li>\n",
    "<li>Matt Damon 's Incredible Pro-Toilet , Anti-Reporter Press Conference</li>\n",
    "<li>... RACCOON ! What Happened To This 1.5 Pound Baby Is Beyond Words . This Beautiful</li>\n",
    "<li>New Video Shows President Obama Meeting His Half-Brother For The Last Words Were Kind Of Religion</li>\n",
    "<li>Reason Behind Them . Kinda Like This . WHOA !</li>\n",
    "<li>Nearly As Bad As These People . And He Had Police</li>\n",
    "<li>Thought This Mom And Dad Did ... Holy Cow .</li>\n",
    "<li>20 Reasons Why Thor Is The Most Epic Secret Santa Exchange I 've Seen Acts of Kindness ,</li>\n",
    "<li>Like Your Mother . Here are 16 Epic Creations From Just a Single Piece of Paper . This Why</li>\n",
    "<li>Be Shocked And Disgusted By Her Ex Led To Something Unexpected ... Yet Beautiful . This Is Cavin I</li>\n",
    "<li>Why You Should Probably See This . Wow . Watch These Rhinos Fly ! Much Endangered .</li>\n",
    "<li>More Beautiful Than This Abandoned Opera House You 'll Agree .</li>\n",
    "<li>Do n't Need A Man Decided To Build Something . Nothing Could Prepare Me The</li>\n",
    "<li>Little Girl Stopped An Olive Garden Manager In His Neighborhood What</li>\n",
    "<li>Something We Should All Be Dead . That 's Dying . Yet Somehow The Last One . I Call A</li>\n",
    "<li>Want To Do It . Evangelicals Do It . Awww x25 .</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Here are some fun headlines that were generated with chosen starter words</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>\"Why Is\"</b>\n",
    "<li>Why Is YOUR Member Of Congress Voting To Keep You In The World ?</li>\n",
    "<li>Why Is Google Sleeping With That Jerk ?</li>\n",
    "<li>Why Is Unforgettable . The Next Day ... Kinda Like This . It 's an Nightmare</li>\n",
    "<li>Why Is This Arrested Woman So Happy ?</li>\n",
    "<li>Why Is This The Most Relatable Macklemore Vine Ever</li>\n",
    "<li>Why Is Even More Unbelievable . Seriously , OMG . Google 'Tucker Carlson ' And 'Gay Marriage . '</li>\n",
    "\n",
    "<b>\"This Is\"</b>\n",
    "<li>This Is Awesome . ( PS : The Untold Story Behind Every Casualty Of War</li>\n",
    "<li>This Is One Of Them Is Facing This NIGHTMARE Right Now .</li>\n",
    "<li>This Is What Creationists Believe About Dinosaurs</li>\n",
    "<li>This Is So Perfect That It Made Me Sick . But THIS is Insanity .</li>\n",
    "<li>This Is How They Came Back Together Is Beautiful . This Is The Most Astounding .</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This was a fun little side project to explore the implementation of a simple Markov chain. It is quite entertaining to see the results!</p>\n",
    "<p>In this notebook, we ingested data from excel sheet, used pandas for data cleaning, and created a Markov chain class that iterated over sentences to build a vocabulary.</p>\n",
    "<p>Using the vocabulary from prior viral headline examples, we created our very own viral headlines. We leveraged structure in the text, simply using bigrams chained to the ensuing third word. The bigrams were linked to a list of possible words (built from real examples), and we used python's random module to pick a possible candidate.</p>\n",
    "<p>This was done iteratively to chain together likely words and formulate cool, intriging headlines, some which I probably would have clicked on. </p>\n",
    "<p>The End... </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>The End ... Amazing . I NEVER Expected What 's Below It Left Me Speechless With Goosebumps . Is </li>\n",
    "<li>The End Made It Unforgettable . The Note They Attached To Him Is Heartbreaking Yet Somehow The Last Thing 'll</li>\n",
    "<li>The End Of The Weirdest 29-Second Traffic Stop Ever</li>\n",
    "<li>The End ... Amazing . I Still Ca n't Be Silent Any Longer '</li>\n",
    "<li>The End Of The Sickest Presidential Insults</li>\n",
    "<li>The End Of The World . And When You Realize What They Seem</li>\n",
    "<li>The End , I Burst Into Tears . The Letter This Trooper Wrote For His Son</li>\n",
    "<li>The End ... WOW .</li>\n",
    "<li>The End Of The World . When You Say 'Happy Holidays </li>\n",
    "<li>The End ... Amazing . I Laughed So Hard . Especially You</li>\n",
    "<li>The End Will Make You Cry . Get A Tissue .</li>\n",
    "<li>The End Made It AWESOME .</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Addendum:\n",
    "# Possible next steps:\n",
    "# - collect more viral headlines; a larger corpus will probably yield better results\n",
    "# - integrate own webscraping mechanism for content acquisition\n",
    "#     - ?scrape http://www.clickhole.com/\n",
    "#     - ?scrape http://www.buzzfeed.com/\n",
    "#             http://www.jeffbullas.com/2015/01/16/22-headlines-that-went-viral-have-these-marketers-cracked-the-code/\n",
    "#     - ?scrape businessinsider\n",
    "#     - ?scrape feedly\n",
    "# - explore text generation with RNNs (Recurrent Neural Networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
